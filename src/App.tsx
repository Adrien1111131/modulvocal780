import React, { useState, useEffect } from 'react';
import TextInput from './components/TextInput';
import VoicePlayer from './components/VoicePlayer';
import LoadingAnimation from './components/LoadingAnimation';
import { generateVoiceWithEnvironment } from './services/elevenLabsAPI';
import { analyzeTextEnvironments } from './services/grokService';
import { logger } from './config/development';
import './App.css';

// Configuration des personnages disponibles
interface Character {
  id: string;
  name: string;
  description: string;
}

const CHARACTERS: Character[] = [
  { id: 'sasha', name: 'Sasha', description: 'Voix grave' },
  { id: 'mael', name: 'Mael', description: 'Voix douce' }
];

// √âtapes du processus de g√©n√©ration
enum ProcessStep {
  IDLE = 'idle',
  CLIPBOARD_READING = 'reading_clipboard',
  TEXT_ANALYZING = 'analyzing_text',
  GENERATING_VOICE = 'generating_voice',
  COMPLETED = 'completed',
  ERROR = 'error'
}

const App: React.FC = () => {
  const [inputText, setInputText] = useState('');
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [detectedEnvironment, setDetectedEnvironment] = useState<string>('default');
  const [detectedEmotion, setDetectedEmotion] = useState<string>('sensuel');
  const [processStep, setProcessStep] = useState<ProcessStep>(ProcessStep.IDLE);
  const [clipboardText, setClipboardText] = useState<string>('');
  const [selectedCharacter, setSelectedCharacter] = useState<string>('sasha'); // Sasha par d√©faut

  // Fonction pour lire l'aper√ßu vocal
  const playVoicePreview = (character: string) => {
    try {
      const audio = new Audio(`/voices/${character}.mp3`);
      audio.volume = 0.7; // Volume mod√©r√©
      audio.play().catch(err => {
        console.error('Erreur lors de la lecture de l\'aper√ßu vocal:', err);
      });
    } catch (err) {
      console.error('Erreur lors du chargement de l\'aper√ßu vocal:', err);
    }
  };

  // R√©cup√©rer le texte depuis sessionStorage lors du chargement initial
  useEffect(() => {
    try {
      // Essayer de r√©cup√©rer le texte depuis sessionStorage
      const storyText = sessionStorage.getItem('storyText');
      
      if (storyText) {
        logger.info('Texte r√©cup√©r√© depuis sessionStorage');
        setInputText(storyText);
      } else {
        logger.info('Aucun texte trouv√© dans sessionStorage');
      }
    } catch (err) {
      logger.error('Erreur lors de la r√©cup√©ration du texte:', err);
    }
  }, []);

  useEffect(() => {
    logger.group('√âtat de l\'application');
    logger.debug('√âtat actuel:', {
      inputText,
      audioUrl,
      isLoading,
      error
    });
    logger.groupEnd();
  }, [inputText, audioUrl, isLoading, error]);

  const handleTextChange = (text: string) => {
    logger.debug('Changement de texte:', text);
    setInputText(text);
    setError(null);

    // Analyser le texte pour d√©tecter l'environnement, l'√©motion et les param√®tres vocaux
    if (text.trim()) {
      analyzeTextEnvironments(text)
        .then(detections => {
          if (detections.length > 0) {
            setDetectedEnvironment(detections[0].environment);
            setDetectedEmotion(detections[0].emotionalTone);
            logger.debug('Environnement d√©tect√©:', detections[0].environment);
            logger.debug('√âmotion d√©tect√©e:', detections[0].emotionalTone);
          }
        })
        .catch(err => {
          logger.error('Erreur lors de la d√©tection de l\'environnement et de l\'√©motion:', err);
          setDetectedEnvironment('default');
          setDetectedEmotion('sensuel');
        });
    } else {
      setDetectedEnvironment('default');
      setDetectedEmotion('sensuel');
    }
  };

  const handleGenerateVoice = async () => {
    logger.group('G√©n√©ration de la voix');
    logger.info('D√©but de la g√©n√©ration');
    
    // Emp√™cher les clics multiples rapides
    if (isLoading) {
      logger.info('G√©n√©ration d√©j√† en cours, ignor√©e');
      logger.groupEnd();
      return;
    }
    
    // Variable pour stocker le texte √† utiliser (presse-papiers ou existant)
    let textToUse = inputText;
    
    // R√©cup√©ration rapide du texte du presse-papiers
    try {
      const clipboardText = await navigator.clipboard.readText();
      if (clipboardText.trim()) {
        logger.info('Texte r√©cup√©r√© depuis le presse-papiers');
        textToUse = clipboardText;
        
        // Mettre √† jour l'√©tat sans attendre
        setInputText(clipboardText);
      }
    } catch (err) {
      // Si l'acc√®s au presse-papiers √©choue, continuer silencieusement avec le texte existant
      logger.info('Utilisation du texte existant (acc√®s au presse-papiers impossible)');
    }
    
    // Utiliser textToUse au lieu de inputText pour les logs et v√©rifications
    logger.debug('Texte √† utiliser:', textToUse);
    logger.debug('Environnement d√©tect√©:', detectedEnvironment);
    logger.debug('√âmotion d√©tect√©e:', detectedEmotion);
    
    // Afficher les logs dans la console du navigateur
    console.log('D√©but de la g√©n√©ration de la voix');
    console.log('Texte:', textToUse);
    console.log('Environnement:', detectedEnvironment);
    console.log('√âmotion:', detectedEmotion);
    
    // V√©rifier si le texte √† utiliser est vide
    if (!textToUse.trim()) {
      const errorMsg = "Veuillez entrer du texte avant de g√©n√©rer la voix";
      logger.warn(errorMsg);
      setError(errorMsg);
      logger.groupEnd();
      return;
    }

    try {
      setIsLoading(true);
      setError(null);
      
      // Utiliser directement le texte sans ajouter de balises d'√©motion
      // L'analyse sera faite par l'API Grok
      logger.debug('Texte √† analyser:', textToUse);

      // Utiliser la m√©thode avec environnement int√©gr√©
      console.log('G√©n√©ration de voix avec environnement int√©gr√©');
      console.log('Personnage s√©lectionn√©:', selectedCharacter);
      const url = await generateVoiceWithEnvironment(textToUse, true, selectedCharacter);
      console.log('G√©n√©ration avec environnement r√©ussie');
      
      logger.info('URL audio re√ßue:', url);
      console.log('URL audio re√ßue:', url);
      
      // V√©rifier que l'URL est valide
      if (!url) {
        throw new Error('URL audio invalide re√ßue');
      }

      setAudioUrl(url);
      logger.info('Audio URL mise √† jour avec succ√®s');
    } catch (err) {
      logger.error('Erreur lors de la g√©n√©ration de la voix:', err);
      let errorMessage = "Erreur lors de la g√©n√©ration de la voix. ";
      
      if (err instanceof Error) {
        errorMessage += err.message;
        logger.error('Message d\'erreur:', err.message);
        logger.error('Stack trace:', err.stack);
      }
      
      setError(errorMessage);
    } finally {
      logger.info('Fin de la g√©n√©ration');
      setIsLoading(false);
      logger.groupEnd();
    }
  };

  // Texte d'exemple pour d√©monstration
  const exampleText = `Je sens mon corps fr√©mir sous tes caresses d√©licates. 
Chaque toucher envoie des vagues de plaisir √† travers ma peau sensible.
Viens plus pr√®s de moi, murmure-t-il doucement √† mon oreille.
Je ne peux plus r√©sister, l'intensit√© me submerge compl√®tement !`;

  const handleStartWithClipboard = async () => {
    try {
      // R√©initialiser les √©tats
      setError(null);
      setIsLoading(true);
      setProcessStep(ProcessStep.CLIPBOARD_READING);
      
      // √âtape 1: Essayer de lire le presse-papiers
      try {
        const text = await navigator.clipboard.readText();
        setClipboardText(text);
        
        if (text.trim()) {
          // √âtape 2: Analyser le texte
          setProcessStep(ProcessStep.TEXT_ANALYZING);
          setInputText(text);
          
          try {
            const detections = await analyzeTextEnvironments(text);
            if (detections.length > 0) {
              setDetectedEnvironment(detections[0].environment);
              setDetectedEmotion(detections[0].emotionalTone);
              logger.debug('Environnement d√©tect√©:', detections[0].environment);
              logger.debug('√âmotion d√©tect√©e:', detections[0].emotionalTone);
            }
          } catch (err) {
            logger.error('Erreur lors de la d√©tection de l\'environnement et de l\'√©motion:', err);
            setDetectedEnvironment('default');
            setDetectedEmotion('sensuel');
          }
          
          // √âtape 3: G√©n√©rer la voix
          setProcessStep(ProcessStep.GENERATING_VOICE);
          await handleGenerateVoice();
          
          // √âtape 4: Termin√©
          setProcessStep(ProcessStep.COMPLETED);
        } else {
          // Utiliser le texte d'exemple si le presse-papiers est vide
          setInputText(exampleText);
          setProcessStep(ProcessStep.TEXT_ANALYZING);
          
          try {
            const detections = await analyzeTextEnvironments(exampleText);
            if (detections.length > 0) {
              setDetectedEnvironment(detections[0].environment);
              setDetectedEmotion(detections[0].emotionalTone);
            }
          } catch (err) {
            setDetectedEnvironment('default');
            setDetectedEmotion('sensuel');
          }
          
          setProcessStep(ProcessStep.GENERATING_VOICE);
          await handleGenerateVoice();
          setProcessStep(ProcessStep.COMPLETED);
        }
      } catch (clipboardErr) {
        // En cas d'erreur d'acc√®s au presse-papiers, utiliser le texte d'exemple
        logger.error('Erreur lors de l\'acc√®s au presse-papiers:', clipboardErr);
        
        // V√©rifier d'abord sessionStorage
        const storyText = sessionStorage.getItem('storyText');
        
        if (storyText && storyText.trim()) {
          setInputText(storyText);
        } else {
          // Utiliser le texte d'exemple si sessionStorage est vide
          setInputText(exampleText);
        }
        
        setProcessStep(ProcessStep.TEXT_ANALYZING);
        
        try {
          const textToAnalyze = storyText && storyText.trim() ? storyText : exampleText;
          const detections = await analyzeTextEnvironments(textToAnalyze);
          if (detections.length > 0) {
            setDetectedEnvironment(detections[0].environment);
            setDetectedEmotion(detections[0].emotionalTone);
          }
        } catch (err) {
          setDetectedEnvironment('default');
          setDetectedEmotion('sensuel');
        }
        
        setProcessStep(ProcessStep.GENERATING_VOICE);
        await handleGenerateVoice();
        setProcessStep(ProcessStep.COMPLETED);
      }
    } catch (err) {
      logger.error('Erreur g√©n√©rale:', err);
      setError("Une erreur est survenue lors de la g√©n√©ration. Veuillez r√©essayer.");
      setProcessStep(ProcessStep.ERROR);
      setIsLoading(false);
    }
  };

  return (
    <div className="app">
      <div className="app-container">
        <div className="controls-section">
          {/* TextInput cach√© mais toujours fonctionnel */}
          <div style={{ display: 'none' }}>
            <TextInput onTextChange={handleTextChange} initialText={inputText} />
          </div>
          
          {/* S√©lecteur de personnages */}
          <div className="character-selector">
            {CHARACTERS.map(character => (
              <div key={character.id} className="character-item">
                <button
                  className={`character-button ${selectedCharacter === character.id ? 'selected' : ''}`}
                  onClick={() => setSelectedCharacter(character.id)}
                  disabled={isLoading}
                >
                  {character.name} - {character.description}
                </button>
                <button
                  className="voice-preview-button"
                  onClick={() => playVoicePreview(character.id)}
                  disabled={isLoading}
                  title={`√âcouter un aper√ßu de la voix de ${character.name}`}
                >
                  üîä
                </button>
              </div>
            ))}
          </div>
          
          {/* Bouton G√©n√©rer la Voix avec fonctionnalit√© de collage */}
          <button 
            onClick={handleGenerateVoice}
            disabled={isLoading}
            className="generate-button"
          >
            {isLoading ? 'G√©n√©ration en cours...' : 'G√©n√©rer la Voix'}
          </button>
          
          {/* Animation de chargement */}
          {isLoading && (
            <LoadingAnimation />
          )}
          
          {error && (
            <div className="error-message">
              {error}
            </div>
          )}
        </div>
        <div className="player-section">
          <VoicePlayer 
            audioUrl={audioUrl} 
            environment={detectedEnvironment}
            emotion={detectedEmotion}
            originalText={inputText}
          />
          {audioUrl && (
            <div className="audio-info">
              Audio g√©n√©r√© avec succ√®s
            </div>
          )}
          
        </div>
      </div>
    </div>
  );
};

export default App;
